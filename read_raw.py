import sys
import argparse
from os import listdir
import os
import pandas as pd
import numpy as np

file_suffix = ".csv"

def load_ft(ft_file):
    """
    Load features from okta_features.txt file into a mapping from the types of the feature to a list of features

    ft_file : string of txt file directory and name

    Returns a tuple containing:
    ft_wtype : dictionary from type to features
    ft       : list of strings of features
    """
    ft = []
    ft_wtype = {}
    with open(ft_file, 'r') as file:
        t = ""
        for l in file:
            if not l.startswith('   '):
                t = l.strip()[:-1]
                ft_wtype[t] = []
            else:
                f = l.strip()
                ft.append(f)
                ft_wtype[t].append(f)
    return ft_wtype, ft

def get_first_non_null(df):
    """
    Find an array of the first non-null values from each row of df. Used to find the first email appeared in ft_wtype['username'](The first is sufficient since they should all match, refer to email.png and email2.png for details)

    df : dataframe

    Returns an 1xn array, where n = number of rows that have values for emails
    """
    a = df.values
    n_rows, n_cols = a.shape
    col_index = pd.isnull(a).argmin(axis=1)
    flat_index = n_cols * np.arange(n_rows) + col_index
    return a.ravel()[flat_index]

def name_logs(file, ft_wtype, ft):
    """
    Name the logs in the file based on features under ft_wtype['username'], and keep only features defined in okta_features.txt

    file: the file directory that ocntains the logs
    ft_wtype: a dictionary from type to features
    ft: features to be extracted from the file

    Return dataframe created from the file with added named column 'user id'
    """
    try:
        df = pd.read_csv(file).loc[:,ft]
    except KeyError as e:
        print("The logs don't have complete features as listed in okta_features.txt", e)
    df['user id'] = get_first_non_null(df.loc[:,ft_wtype['username']])
    return df


def save_csv(df, file, index_col = None):
    """
    Save a pandas dataframe into a file, by default without an index (index here is a column of numbers started from 0, which is not very useful).

    df: pandas dataframe
    file: the file path for this df to be saved
    index_col: a boolean to set the index option 
    """
    directory, file = os.path.split(file)
    i = True if index_col else False
    df.to_csv(os.path.join(directory, "named_"+file), index = i)
    print("Saved named csv!")

def main(files):
    """
    For each file needed to be preprocessed, it names each log by collapsing emails from the username group defined in okta_features.txt, and then drop the log with no associated emails. The expected csv outputs should only have columns as defined in okta_features.txt, and the very first column is the eventId generated by Okta, eventId will later be read as the index column and not included in the model training, so it is IMPORTANT to keep eventId the first column of the csv.

    files: list of file paths
    """

    def update_agent_helper(r):
        """
        Helper function for cleaning the agent field. Downloaded csv okta files have hard to understand encoding in the agent field, ex. 00u16adszk2890omo0h8\n Okta AD Agent/3.4.3 (Microsoft Windows NT 6.2.9200.0; .NET CLR 4.0.30319.42000; 64-bit OS; 64-bit Process; sslpinning=disabled)

        r: row of the dataframe that contains a single log event

        Returns cleaned agent value
        """
        agent = r['agent'].splitlines()
        if len(agent) > 2:
            print(len(agent), agent)
        agent = agent[1] if len(agent) > 1 else agent[0]
        return agent

    #Read features with type, and features from okta_features.txt
    ft_wtype, ft = load_ft('okta_features.txt')
    for file in files:
        #Extract columns, collapse emails, and throw away irrelevant rows without emails
        named_df = name_logs(file, ft_wtype, ft)
        df = named_df[pd.notnull(named_df['user id'])]

        #Clean the agent column
        df.loc[:,'agent'] = df.loc[:,'agent'].astype('str')
        df.loc[:,'agent'] = df.apply(update_agent_helper, axis = 1)

        #Throw away email columns defined in ft_wtype['username'] and keep 'user id' column only
        df = df.drop(ft_wtype['username'], axis=1)

        #eventId is set to be the index, so it's always the first column
        df = df.set_index('eventId') 
        save_csv(df, file, 'eventId')

if __name__ == "__main__":
    """
    Run the script to read raw data pulled from Splunk. Raw data will be extracted based on the columns defined in okta_features.txt and named with user emails.

    arg:
        -p prefix of the raw csv data, ex. okta_
        -d relative directory of the raw csv data from this script directory, ex. data\
        -f the file name of a specific raw csv data without the .csv suffix, ex. okta_8_11
    """
    parser = argparse.ArgumentParser()
    parser.add_argument('-d', action='store',
                    dest='directory',
                    default = '',
                    help='The relative directory for this read operation')
    parser.add_argument('-p', action='store',
                    dest='prefix',
                    help='Read all raw files started with a given prefix under the directory')
    parser.add_argument('-f', action='store',
                        dest='file',
                        help='Only read a specific raw file with a given file name(without suffix)')
    results = parser.parse_args()
    root = os.path.abspath(os.path.dirname(__file__))

    if (results.prefix and results.file) or not (results.prefix or results.file):
        parser.error("Specify either -p or -f, but NOT both!")

    if len(results.directory) == 0:
        files = [f for f in listdir() if f.endswith(file_suffix) and f.startswith(results.prefix)] if results.prefix else [results.file+file_suffix]
    else:
        files = [os.path.join(root, results.directory, f) for f in listdir(results.directory) if f.endswith(file_suffix) and f.startswith(results.prefix)] if results.prefix else [results.directory+"\\"+results.file+file_suffix]
    main(files)



