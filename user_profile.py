import pandas as pd
import numpy as np
from pathlib import Path
import os
import argparse
from os import listdir
import os.path
import pickle
import csv
import data_description as ddes
import random

data_dir = os.path.join(os.path.abspath(os.path.dirname(__file__)), "data")
output_dir = os.path.join(os.path.abspath(os.path.dirname(__file__)), "users")
prefix = "sys_encoded_" # default value for encoding the user file, "named_" should be the prefix if raw files are extracted instead
file_suffix = ".csv"
max_count = 10

def random_email_list(df_list, l):
    """
    Randomly generate a list of user emails with length l whose number of records is at least max_count in each dataframe

    df_list: a list of dataframes containing the okta logs
    l: length
    """
    user = set()
    for df in df_list:
        if len(user) == 0:
            user = set(user_count_filter(df, max_count).index)
            continue
        users = set.intersection(user, set(user_count_filter(df, max_count).index))
    return random.sample(user, l)

def user_count_filter(df, x):
    """
    Filter users based on the number of records in the dataframe

    df: the dataframe containing the event logs
    x: the threshold for the number of records
    """
    res = df.groupby('user id')['user id'].agg('count')
    return res[res > x]

def get_df(files, i = 0):
    """
    Get a list of dataframes from a list of files, with index being the first column by default(the eventId)

    files: a list of file paths
    i: index_col
    """
    return [pd.read_csv(file, index_col = i, dtype=object, encoding = "cp1252") for file in files] #MAKE SURE eventId is set as index during read_raw(in named_okta_ files) for i = 0

def encode_col(df, user, col):
    """
    Encode the column for a user

    df: the dataframe containing the column
    user: the user's email
    col: the column to be encoded
    """
    mapper = ddes.load_types(df, col, filename = os.path.join(output_dir, col+"_"+user))
    df[col] = df[col].apply(lambda x: mapper[x] if pd.notnull(x) else 0)
    return df


def main(files, drop, useremails = [], l = 0):
    """
    Encode the files for specific users, drop redunant columns, and output a ready-to-train csv if drop is True, otherwise find the events generated by specific users and output the csvs

    files: list of system-level encoded files
    drop: False for user's raw data, True for user's encoded data
    useremails: list of user emails to extract the profiles
    l: positive integer for the length of random list of user emails to be generated
    """
    df_list = get_df(files)
    if l > 0:
        useremails = random_email_list(df_list, l)
    for user in useremails:
        frames = [df.loc[df['user id'] == user] for df in df_list]
        user_df = pd.concat(frames)
        if drop:
            for col in ['agent', 'message', 'src_ip']:
                user_df = encode_col(user_df, user, col)
            user_df = user_df.drop(['user id', 'src_city', 'user_work_city'], axis = 1)
            ddes.write_to(os.path.join(output_dir, user+".csv"), user_df, append=False, index_col = 'eventId')
        else:
            user_df = pd.concat(frames)
            ddes.write_to(os.path.join(output_dir, "raw_"+user+".csv"), user_df, append=False, index_col = 'eventId')


if __name__ == "__main__":
    """
    Run the script to generate completely encoded files to be ready for the model. It encodes columns at user level, meaning that each user has a different encoding scheme.

    arg:
        -p prefix of the encoded system-level csv data, ex. sys_
        -d relative directory of the raw csv data from this script directory, ex. data\
        -r randomly select n number of users to generate the profiles, ex. 3
        -lu list of user emails whose profiles are generated, ex. chuwu@adobe.com, braviak@adobe.com
        -drop drop and encode the file, if -drop not selected, raw files belonging to the specified users are returned
    """
    parser = argparse.ArgumentParser()
    p = parser.add_mutually_exclusive_group()
    p.add_argument('-lu', action='store',
                        nargs = "+",
                        dest='list_useremail',
                        help='A list of user emails to extract')
    p.add_argument('-r',  nargs='?', const=1, type=int,
                        dest = 'random',
                        help='Generate a ramdom list of user emails with len')
    parser.add_argument('-p', action='store', required = True,
                        dest='prefix',
                        help='Work on all files started with a given prefix under the directory')
    parser.add_argument('-d', action='store',
                    dest='directory',
                    default = data_dir,
                    help='The directory for this read operation, ex. data\\')
    parser.add_argument('-drop', action='store_true', dest="drop")
    results = parser.parse_args()
    root = os.path.abspath(os.path.dirname(__file__))

    if len(results.directory) == 0:
        files = [f for f in listdir() if f.endswith(file_suffix) and f.startswith(results.prefix)] if results.prefix else [results.file+file_suffix]
    else:
        files = [os.path.join(root, results.directory, f) for f in listdir(results.directory) if f.endswith(file_suffix) and f.startswith(results.prefix)] if results.prefix else [results.directory+"\\"+results.file+file_suffix]

    if results.list_useremail:
        main(files, drop = results.drop, useremails = results.list_useremail)
    elif results.random > 0:
        main(files, drop = results.drop,  l = results.random)
    else:
        parser.error("Either -lu or -r must be specified, but NOT both!")
